\chapter{Utilizzo di Gemini come LLM e Spatial Understanding}
\pagestyle{plain}
In questo progetto è stato fatto uso di una LLM per il riconoscimento degli ingredienti e la successiva creazione di tre ricette. Fra tutte le LLM disponibili è stato scelto Gemini, la LLM sviluppata da Google, per la sua capacità di comprendere le immagini e l'API gratuita.

\section{Cosa è una LLM}
Un Large Language Model (LLM) è un modello di intelligenza artificiale in grado principalmente di riconoscere e generare testo. Gli LLM sono addestrati su grandi quantità di dati tramite l'uso del machine learning, nello specifico un particolare tipo di rete neurale chiamato Transformer. Per essere allenati in campi specifici, senza perdere il modello generato, viene utilizzato il fine-tuning, un processo che permette di specializzare il modello su un compito specifico.
Le informazioni che le LLM restituiscono sono affidabili quanto lo sono i dati che gli sono stati forniti durante l'allenamento, quindi se nei dati sono presenti delle informazioni sbagliate queste verranno date per giuste alle domande poste all'LLM. A volte invece gli LLM possono creare delle false informazioni dal nulla, questo fenomeno si chiama allucinazione, ad esempio nel 2022 venne chiesto a ChatGPT di creare un articolo sulla compagnia Tesla, l'LLM creò l'articolo, dove però la maggior parte delle informazioni erano inventate.\cite{LLMCloudflare}

Gli usi di una LLM sono vari, tra cui:
\begin{itemize}
    \item \textbf{Generazione di testo}: Creazione di email, blog, articoli e molto altro
    \item \textbf{Riassumere testo}: Riassumere lunghi articoli, notizie ma anche report aziendali
    \item \textbf{Generazione di codice}: Generare codice per la maggior parte di linguaggi di programmazione per aiutare il programmatore in compiti ripetitivi 
    \item \textbf{Traduzione}: Tradurre i testi in varie lingue, fornendo una traduzione accurata che prende nota anche del contesto delle parole
    \item \textbf{Accessibilità}: Aiutare le persone con disabilità a interagire con l'ambiente circostante, ad esempio generando descrizioni di immagini per persone non vedenti, tecnologia ancora in sviluppo con la recentissima versione di Gemini Live
\end{itemize}
\cite{LLMIBM} \cite{GeminiLiveBlog} \cite{GeminiLiveYoutube}

\section{Prompting}
I prompt sono utilizzati per interagire con le LLM, di solito sono delle domande, e in generale delle richieste testuali fatte dall'utente. Per ottenere le risposte volute nel prompt, oltre a porre la domanda o l'azione da fare, è necessario fornire, se necessario, il contesto, e se si vuole essere più specifici anche il formato della risposta, ad esempio un elenco puntato oppure un testo di poche righe. Da tenere a mente che però le LLM potrebbero non del tutto seguire le istruzioni fornite, soprattutto se si fanno richieste troppo specifiche come il numero di caratteri. \cite{PromptingNvidia} \cite{PromptingGoogle}

\section{Utilizzo di Gemini per Spatial Understanding}
Gemini offre la possibilità di utilizzare le immagini come input, e ottenere, oltre che una descrizione dell'immagine anche informazioni più specifiche e interessanti. Lo Spatial Understanding è una funzionalità che consente all'LLM di identificare gli oggetti presenti nell'immagine, restituendone i nomi e le relative coordinate spaziali.. Si può provare questa funzionalità nel sito di Gemini Studio nella sezione "Build" sotto il nome di "Spatial Understanding". Nel nostro caso si darà alla LLM l'immagine di un tavolo o in generale di un piano in cui sono poggiati gli ingredienti e si chiederà all'LLM di restituire i nomi degli ingredienti e le relative posizioni.
\section{Utilizzo di Gemini come LLM}
Una volta ottenuti i nomi degli ingredienti, questi verranno dati a Gemini, a cui sarà chiesto di generare tre ricette utilizzando solo gli ingredienti forniti.

